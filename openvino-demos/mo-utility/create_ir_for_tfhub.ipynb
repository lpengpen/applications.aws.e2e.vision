{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Convert TFHub Models to OpenVINO IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to convert TFHub models to OpenVINO IR format.\n",
    "\n",
    "See list of supported models in TFHub-SupportedModelList\n",
    "\n",
    "Following are the steps\n",
    "- Enable Python3.8 and Install Python3.8 Devel packages.\n",
    "- Install necessary pip packages.\n",
    "- [Optional] In AWS Sagemaker environment, remove few unused conda envs. This will ensure we have enought disk space.\n",
    "- Select a model from the supported list - TFHub-SupportedModelList\n",
    "- Convert TFHub Model to OpenVINO IR\n",
    "- [Optional] Run OpenVINO benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Python3.8 and Install Python3.8 Devel packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo amazon-linux-extras enable python3.8\n",
    "!sudo yum -y install python38 python38-devel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install necessary pip packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Removed few unused conda envs to create free space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash remove-unused-conda-envs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert TFHub Models to OpenVINO IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide below details:\n",
    "\n",
    "`bucket_name` - S3 bucket name with \"sagemaker\" as part of the name.\n",
    "Example: sagemaker-ir-creation\n",
    "\n",
    "`tfhub_model_url` - TfHub model URL. See supported list in TFHub-SupportedModelList\n",
    "\n",
    "`input_shape` - Input shape of the selected model. See TFHub-SupportedModelList\n",
    "\n",
    "`precision_type` - Use either FP32 or FP16\n",
    "\n",
    "#### NOTE: If the bucket does not exist then it will be created.\n",
    "\n",
    "#### Example:\n",
    "```\n",
    "bucket_name = \"sagemaker-ir-creation\"\n",
    "tfhub_model_url = \"https://tfhub.dev/google/efficientnet/b0/classification/1\"\n",
    "input_shape = \"1,224,224,3\"\n",
    "precision_type = \"FP32\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"sagemaker-ir-creation\"\n",
    "# See supported list in TFHub-SupportedModelList in the repo for URLs and input shapes\n",
    "tfhub_model_url = \"https://tfhub.dev/google/efficientnet/b0/classification/1\"\n",
    "input_shape = \"1,224,224,3\"\n",
    "precision_type = \"FP32\" # FP16 also supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IR params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_arr = tfhub_model_url.split(\"/\")\n",
    "url_arr_len = len(url_arr)\n",
    "model_name = \"\".join([url_arr[url_arr_len - 4], \"-\", url_arr[url_arr_len - 3]])\n",
    "output_dir = \"\".join([\"./\", model_name.replace('.','-'), \"-tfhub-\", precision_type])\n",
    "if isinstance(input_shape, str):\n",
    "    input_shape = [int(i) for i in input_shape.split(\",\")]\n",
    "\n",
    "create_ir_params = {\n",
    "    \"tfhub_model_url\": tfhub_model_url,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"mo_params\": {\n",
    "        \"input_shape\": input_shape,\n",
    "        \"data_type\": precision_type,\n",
    "        \"model_name\": model_name\n",
    "    },\n",
    "    \"bucket_name\": bucket_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger OpenVINO IR creation and upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ov_utils import create_ir\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_ir(create_ir_params) # This will create IR and upload to S3 bucket.\n",
    "    print (f\"IR files created for model:{model_name} and the same is uploaded in S3:{bucket_name}\")\n",
    "    print (f\"IR files are located at : {output_dir}/IR_models/\")\n",
    "except Exception as err:\n",
    "    print(f\"FAILED: Please find the error details below:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Sample Benchmark with OpenVINO IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_ir_path = \"\".join([output_dir,\"/IR_models/\", precision_type, \"/\", model_name,\".xml\"])\n",
    "benchmark_cmd = \"\".join([\"benchmark_app -m \", ov_ir_path, \" -niter 50\"])\n",
    "print(f\"OpenVINO Benchmarking CMD:\\n {benchmark_cmd} \\n\")\n",
    "\n",
    "# Run sample openvino bechmark\n",
    "!{benchmark_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
